{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajasri433/python/blob/main/untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J7DBKTgg4qoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c22943-7fc7-4ce9-8d6d-96281079c055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, faiss-cpu\n",
            "Successfully installed PyMuPDF-1.25.1 faiss-cpu-1.9.0.post1\n"
          ]
        }
      ],
      "source": [
        "pip install PyMuPDF sentence-transformers faiss-cpu transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Initialize models and tokenizer\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "llm = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Function to extract text from PDF using PyMuPDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text_data = []\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text()\n",
        "        text_data.append(text)\n",
        "    return text_data\n",
        "\n",
        "# Function to create chunks of text\n",
        "def create_chunks(text, chunk_size=512):\n",
        "    sentences = text.split('. ')\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for sentence in sentences:\n",
        "        if current_length + len(sentence.split()) > chunk_size:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(sentence)\n",
        "        current_length += len(sentence.split())\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "# Function to create embeddings and store in vector database\n",
        "def store_embeddings(chunks):\n",
        "    embeddings = embedding_model.encode(chunks)\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "    return index, embeddings\n",
        "\n",
        "# Function to handle queries\n",
        "def handle_query(query, index, chunks):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    D, I = index.search(query_embedding, k=5)\n",
        "    retrieved_chunks = [chunks[i] for i in I[0]]\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Function to generate response using LLM\n",
        "def generate_response(query, retrieved_chunks):\n",
        "    context = '\\n'.join(retrieved_chunks)\n",
        "    input_text = f\"Query: {query}\\nContext: {context}\"\n",
        "    inputs = tokenizer(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
        "    summary_ids = llm.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Function to handle comparison queries\n",
        "def handle_comparison_query(query, index, chunks):\n",
        "    # This can be improved to parse specific comparison-related logic\n",
        "    retrieved_chunks = handle_query(query, index, chunks)\n",
        "    response = generate_response(query, retrieved_chunks)\n",
        "    return response\n",
        "\n",
        "# Main function\n",
        "def main(pdf_path, query, is_comparison=False):\n",
        "    text_data = extract_text_from_pdf(pdf_path)\n",
        "    chunks = []\n",
        "    for text in text_data:\n",
        "        chunks.extend(create_chunks(text))\n",
        "\n",
        "    index, _ = store_embeddings(chunks)\n",
        "\n",
        "    if is_comparison:\n",
        "        response = handle_comparison_query(query, index, chunks)\n",
        "    else:\n",
        "        retrieved_chunks = handle_query(query, index, chunks)\n",
        "        response = generate_response(query, retrieved_chunks)\n",
        "\n",
        "    # Print the query, context, and response\n",
        "    print(\"\\033[1mQuery:\\033[0m\", query)\n",
        "    print('\\n'.join(retrieved_chunks))\n",
        "    print(\"\\033[1mResponse:\\033[0m\", response)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "pdf_path = '/content/Tables- Charts- and Graphs with Examples from History- Economics- Education- Psychology- Urban Affairs and Everyday Life - 2017-2018.pdf'\n",
        "\n",
        "# Additional query\n",
        "query2 = 'From page 6 get the tabular data'\n",
        "response2 = main(pdf_path, query2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixz-gNXrKnzA",
        "outputId": "c256b4e3-8d0b-4e6a-be16-48addb115cb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mQuery:\u001b[0m From page 6 get the tabular data\n",
            "Tables, Charts, and \n",
            "Graphs Basics\n",
            "\n",
            "x\n",
            "y\n",
            "0\n",
            "0\n",
            "1\n",
            "3\n",
            "2\n",
            "6\n",
            "3\n",
            "9\n",
            "4\n",
            "12\n",
            "5\n",
            "15\n",
            "6\n",
            "18\n",
            "7\n",
            "21\n",
            "8\n",
            "24\n",
            "•\n",
            "If given a table of data, we should be able to plot it  Below is \n",
            "some sample data; plot the data with x on the x-axis and y on the \n",
            "y-axis.\n",
            "\n",
            "Tables, Charts, and \n",
            "Graphs \n",
            "with Examples from History, Economics, \n",
            "Education, Psychology, Urban Affairs and \n",
            "Everyday Life\n",
            "REVISED: MICHAEL LOLKUS 2018\n",
            "\n",
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "•\n",
            "Below is a plot of the data on the table from the previous \n",
            "slide  Notice that this plot is a straight line meaning that a \n",
            "linear equation must have generated this data.\n",
            "•\n",
            "What if the data is not generated by a linear equation?  We can \n",
            "fit the data using a linear regression and use that line as an \n",
            "approximation to the data  Regressions are beyond the scope of \n",
            "this workshop.\n",
            "\n",
            "Table of Yearly U.S GDP by \n",
            "Industry (in millions of dollars)\n",
            "Year\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "All Industries\n",
            "26093515\n",
            "27535971\n",
            "28663246\n",
            "29601191\n",
            "30895407\n",
            "31397023\n",
            "Manufacturing\n",
            "4992521\n",
            "5581942\n",
            "5841608\n",
            "5953299\n",
            "6047477\n",
            "5829554\n",
            "Finance,\n",
            "Insurance, Real \n",
            "Estate, Rental, \n",
            "Leasing\n",
            "4522451\n",
            "4618678\n",
            "4797313\n",
            "5031881\n",
            "5339678\n",
            "5597018\n",
            "Arts, \n",
            "Entertainment, \n",
            "Recreation, \n",
            "Accommodation,\n",
            "and Food Service\n",
            "964032\n",
            "1015238\n",
            "1076249\n",
            "1120496\n",
            "1189646\n",
            "1283813\n",
            "Other\n",
            "15614511\n",
            "16320113\n",
            "16948076\n",
            "17495515\n",
            "18318606\n",
            "18686638\n",
            "Source: U.S Bureau of Labor Statistics\n",
            "\n",
            "\u001b[1mResponse:\u001b[0m Query: From page 6 get the tabular data. Basics: Tables, Charts, and Graphs. Data: Table of Yearly U.S GDP by Industry (in millions of dollars) Data: Data from History, Economics, Education, Psychology, Urban Affairs and  Everyday Life.\n"
          ]
        }
      ]
    }
  ]
}